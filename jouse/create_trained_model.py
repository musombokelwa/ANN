#!/usr/bin/env python3
"""
Script pour cr√©er un mod√®le entra√Æn√© de test
"""

import os
import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler

print("ü§ñ Cr√©ation d'un mod√®le entra√Æn√© pour les tests...\n")

# Cr√©er des donn√©es d'entra√Ænement simul√©es
print(" G√©n√©ration de donn√©es synth√©tiques...")
np.random.seed(42)

# 200 samples
n_samples = 200

# Colonnes num√©riques: Download, Upload, Latence, Jitter, Loss
X_numeric = np.random.rand(n_samples, 5) * 200  # Valeurs entre 0-200

# Colonnes cat√©goriques encod√©es: Op√©rateur, Quartier, Type r√©seau  
X_categorical = np.random.randint(0, 50, size=(n_samples, 3))

# Combiner
X = np.hstack([X_categorical, X_numeric]).astype('float32')

# Cr√©er les labels cibles (0: Bonne, 1: Moyenne, 2: Mauvaise)
# Logique simple: r√©partir les 3 classes uniform√©ment
y = np.array([i % 3 for i in range(n_samples)], dtype='int32')
np.random.shuffle(y)

print(f"‚úÖ {n_samples} samples cr√©√©s")
print(f"   Classes: Bonne={sum(y==0)}, Moyenne={sum(y==1)}, Mauvaise={sum(y==2)}\n")

# Entra√Æner le mod√®le
print(" Entra√Ænement du mod√®le RandomForest...")
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=5,
    random_state=42,
    n_jobs=-1
)

model.fit(X, y)
print("‚úÖ Mod√®le entra√Æn√©!\n")

# Cr√©er et entra√Æner le scaler
print(" Cr√©ation du Scaler...")
scaler = MinMaxScaler()
scaler.fit(X[:, 3:8])  # Normaliser les colonnes num√©riques (indices 3-8)
print("‚úÖ Scaler cr√©√©!\n")

# Sauvegarder
model_path = 'model/modele_non_entraine.pkl'
scaler_path = 'model/scaler.pkl'

print(" Sauvegarde des fichiers...")
joblib.dump(model, model_path)
print(f"   ‚úÖ {model_path}")

joblib.dump(scaler, scaler_path)
print(f"   ‚úÖ {scaler_path}\n")

# Test rapide
print("üß™ Test du mod√®le...")
# 3 cat√©gories (Op√©rateur, Quartier, Type r√©seau) + 5 num√©riques (Download, Upload, Latence, Jitter, Loss)
test_data = np.array([
    [10, 20, 100, 50, 10, 2, 0.1, 5]  # 8 colonnes totales
], dtype='float32')

test_categorical = test_data[:, :3]
test_numeric = test_data[:, 3:]

# Normaliser les colonnes num√©riques
test_numeric_scaled = scaler.transform(test_numeric)

# Recombiner: cat√©gories + num√©riques normalis√©es
test_data_scaled = np.hstack([test_categorical, test_numeric_scaled])

prediction = model.predict(test_data_scaled)
proba = model.predict_proba(test_data_scaled)

classes = ['Bonne', 'Moyenne', 'Mauvaise']
predicted_class = prediction[0]

print(f"   Pr√©diction: {classes[predicted_class]}")
print(f"   Probabilit√©s: Bonne={proba[0][0]:.2%}, Moyenne={proba[0][1]:.2%}, Mauvaise={proba[0][2]:.2%}")
print("\n‚úÖ Mod√®le pr√™t √† l'emploi!")
